{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw , y_raw = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_raw.shape)\n",
    "print(y_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframes converted into numpy arrays\n",
    "X_raw_np = X_raw.to_numpy()\n",
    "y_raw_np = y_raw.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.  18.  18.  18. 126. 136. 175.  26. 166. 255. 247. 127.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.  30.  36.  94. 154. 170. 253. 253. 253. 253. 253. 225. 172. 253. 242. 195.  64.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.  49. 238. 253. 253. 253. 253. 253. 253. 253. 253. 251.  93.  82.  82.  56.  39.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.  18. 219. 253. 253. 253. 253. 253. 198. 182. 247. 241.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.  80. 156. 107. 253. 253. 205.  11.   0.  43. 154.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  14.   1. 154. 253.  90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 139. 253. 190.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  11. 190. 253.  70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  35. 241. 225. 160. 108.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  81. 240. 253. 253. 119.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  45. 186. 253. 253. 150.  27.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  16.  93. 252. 253. 187.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 249. 253. 249.  64.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  46. 130. 183. 253. 253. 207.   2.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  39. 148. 229. 253. 253. 253. 250. 182.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  24. 114. 221. 253. 253. 253. 253. 201.  78.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.  23.  66. 213. 253. 253. 253. 253. 198.  81.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.  18. 171. 219. 253. 253. 253. 253. 195.  80.   9.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.  55. 172. 226. 253. 253. 253. 253. 244. 133.  11.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0. 136. 253. 253. 253. 212. 135. 132.  16.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "#Thought it'd be cool to see the images as a matrix\n",
    "\n",
    "np.set_printoptions(linewidth=2000)\n",
    "print(X_raw_np[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label is 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index=0\n",
    "\n",
    "plt.imshow(X_raw_np[index].reshape(28,28), cmap=cm.binary)\n",
    "print(\"Label is\", y_raw_np[index])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data split into 60% training, 20% validation & 20% test\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_raw_np, y_raw_np, test_size=0.4)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train = (42000, 784)\n",
      "y_train = (42000,)\n",
      "X_val = (14000, 784)\n",
      "y_val = (14000,)\n",
      "X_test = (14000, 784)\n",
      "y_test = (14000,)\n"
     ]
    }
   ],
   "source": [
    "#Checking dimensions\n",
    "\n",
    "print(\"X_train =\",X_train.shape)\n",
    "print(\"y_train =\",y_train.shape)\n",
    "print(\"X_val =\", X_val.shape)\n",
    "print(\"y_val =\", y_val.shape)\n",
    "print(\"X_test =\", X_test.shape)\n",
    "print(\"y_test =\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing values to between 0-1 \n",
    "X_train, X_val, X_test = np.array(X_train/255), np.array(X_val/255), np.array(X_test/255)\n",
    "\n",
    "\n",
    "# Changing y data into binary matricies such that each row is a vector with 0s and 1 which indicates the label.\n",
    "# this is done so that a MSE error can be calulated while using sigmoid activation function for the output layer.\n",
    "\n",
    "\n",
    "#y_train into binary matrix\n",
    "y_train_binary = np.zeros((42000,10))\n",
    "\n",
    "j = 0\n",
    "for i in range(0, len(y_train)):\n",
    "    \n",
    "\n",
    "\n",
    "    if int(y_train[i]) == 0:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_train[i]) == 1:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_train[i]) == 2:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "    elif int(y_train[i]) == 3:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_train[i]) == 4:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_train[i]) == 5:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "    elif int(y_train[i]) == 6:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_train[i]) == 7:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_train[i]) == 8:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_train[i]) == 9:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1]) \n",
    "        j += 1\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "#y_val into binary matrix\n",
    "y_val_binary = np.zeros((14000,10))\n",
    "\n",
    "j = 0\n",
    "for i in range(0, len(y_val)):\n",
    "    \n",
    "\n",
    "\n",
    "    if int(y_val[i]) == 0:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_val[i]) == 1:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_val[i]) == 2:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "    elif int(y_val[i]) == 3:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_val[i]) == 4:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_val[i]) == 5:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "    elif int(y_val[i]) == 6:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_val[i]) == 7:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_val[i]) == 8:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_val[i]) == 9:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1]) \n",
    "        j += 1\n",
    "\n",
    "\n",
    "\n",
    "#y_test into binary matrix\n",
    "y_test_binary = np.zeros((14000,10))\n",
    "\n",
    "j = 0\n",
    "for i in range(0, len(y_test)):\n",
    "    \n",
    "\n",
    "\n",
    "    if int(y_test[i]) == 0:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_test[i]) == 1:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_test[i]) == 2:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "    elif int(y_test[i]) == 3:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_test[i]) == 4:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_test[i]) == 5:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "    elif int(y_test[i]) == 6:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_test[i]) == 7:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_test[i]) == 8:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_test[i]) == 9:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1]) \n",
    "        j += 1\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **NN begins**\n",
    "\n",
    "##### In this implementation everything is manually coded.\n",
    "\n",
    "##### NN specification:\n",
    "\n",
    "L = 4, L1 has 784 neurons, 2 hidden layers have 16 neurons each and the output layer has 10, one for each digit.\n",
    "\n",
    "\n",
    "W2 has dimensions 16 x 784 <br>\n",
    "W3 has dimensions 16 x 16 <br>\n",
    "W4 has dimensions 10 x 16 <br>\n",
    "\n",
    "b2-3 has dimensions 16 x 1 <br>\n",
    "b4 has dimensions 10 x 1 <br>\n",
    "\n",
    "\n",
    "##### Procedure:\n",
    "1. Manually generate all weight matricies and biases then initalize randomly \n",
    "\n",
    "***\n",
    "\n",
    "2. Split data into mini batches\n",
    "3. Feedforward a single training example from a given batch\n",
    "4. Calulate cost \n",
    "5. Backprop and calulate the gradient\n",
    "\n",
    "***\n",
    "\n",
    "6. Repeat steps 3-5 for all images in first batch\n",
    "\n",
    "***\n",
    "\n",
    "7. Average the gradient of the cost for all images in the first batch\n",
    "8. apply gradient decent step to update the weights\n",
    "\n",
    "***\n",
    "\n",
    "9. Repeat 3-8 for all minibatches\n",
    "\n",
    "***\n",
    "10. shuffle data\n",
    "11. Repeat 2-9 for a given number of 'epochs' \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating and initializing matricies & biases randomly to values between -5 - 5\n",
    "\n",
    "#W2 = np.random.uniform(low = -5,high= 5,size =(16, 784))\n",
    "#W3 = np.random.uniform(low = -5,high= 5,size =(16, 16))\n",
    "#W4 = np.random.uniform(low = -5,high= 5,size =(10, 16))\n",
    "\n",
    "#b2 = np.random.uniform(low = -5,high= 5,size =(16, 1))\n",
    "#b3 = np.random.uniform(low = -5,high= 5,size =(16, 1))\n",
    "#b4 = np.random.uniform(low = -5,high= 5,size =(10, 1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for shuffling and creating mini batches by turning X and y into tensors\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def create_mini_batch(X_input, y_input, mini_batch_size):\n",
    "\n",
    "    X_shuffled, y_shuffled = shuffle(X_input, y_input)\n",
    "\n",
    "    reshaped_dim = int(len(X_shuffled)/mini_batch_size)\n",
    "\n",
    "    X_minibatches_tensor = X_shuffled.reshape(reshaped_dim, mini_batch_size,  X_shuffled.shape[1] )\n",
    "\n",
    "    y_minibatches_tensor = y_shuffled.reshape(reshaped_dim, mini_batch_size,  y_shuffled.shape[1])\n",
    "\n",
    "\n",
    "    return X_minibatches_tensor, y_minibatches_tensor\n",
    "\n",
    "\n",
    "# The above function outputs a X tensor such that each matrix being a mini batch with each row being an image\n",
    "# it outputs y a 3 tendor with the input being the y binary matricies. the matricies of the tensor are a given minibatch\n",
    "#  and the rows are the labels of each image. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "# Derivative of sigmoid \n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z)*(1.0-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedsforward one layer and outputs Z and activations of the next layer. \n",
    "def feedforward(a, W, b):\n",
    "    Z_l = np.dot(W, a) + b\n",
    "    A_l = sigmoid(Z_l)\n",
    "\n",
    "    return Z_l, A_l \n",
    "\n",
    "#input data X needs to be fed in column vec form .reshape(784, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE cost function\n",
    "\n",
    "def Cost_per_example(a_L, Y):\n",
    "    e2 = ((a_L - Y)**2)/2\n",
    "    cost = e2.sum()\n",
    "    return cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backpropagation\n",
    "\n",
    "def backprop(X, Y, W2, W3, W4, B2, B3, B4, batch_no, example_no):\n",
    "\n",
    "    \n",
    "    Z_2, a_2 = feedforward(X[batch_no][example_no].reshape(784,1), W2, B2)\n",
    "    Z_3, a_3 = feedforward(a_2, W3, B3)\n",
    "    Z_L, a_L = feedforward(a_3, W4, B4)\n",
    "\n",
    "    delta_L = np.multiply(((a_L - Y[batch_no][example_no].reshape(10,1))**2), sigmoid_prime(Z_L))\n",
    "    delta_3 = np.multiply(np.dot(W4.T, delta_L), sigmoid_prime(Z_3))\n",
    "    delta_2 = np.multiply(np.dot(W3.T, delta_3), sigmoid_prime(Z_2))\n",
    "\n",
    "    #creating derivatives of cost w.r.t weight matricies\n",
    "\n",
    "    d_W4 = np.zeros((10, 16))\n",
    "    for j in range(10):\n",
    "        for k in range(16):\n",
    "            d_W4[j][k] += delta_L[j]*a_3[k]\n",
    "\n",
    "    d_W3 = np.zeros((16, 16))\n",
    "    for j in range(16):\n",
    "        for k in range(16):\n",
    "            d_W3[j][k] += delta_3[j]*a_2[k]\n",
    "\n",
    "\n",
    "    d_W2 = np.zeros((16, 784))\n",
    "    for j in range(16):\n",
    "        for k in range(784):\n",
    "            d_W2[j][k] += delta_2[j]*X[batch_no][example_no].reshape(784,1)[k]\n",
    "\n",
    "\n",
    "    d_b4, d_b3, d_b2 = delta_L, delta_3, delta_2\n",
    "\n",
    "\n",
    "    return d_W2, d_W3, d_W4, d_b2, d_b3, d_b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that updates the weights using gradient decent \n",
    "\n",
    "def update_weights(X, Y, W2, W3, W4, B2, B3, B4, batch_no, batch_size, learning_rate):\n",
    "\n",
    "    d_W2_av = np.zeros(W2.shape)\n",
    "    d_W3_av = np.zeros(W3.shape)\n",
    "    d_W4_av = np.zeros(W4.shape)\n",
    "\n",
    "    d_b2_av = np.zeros(B2.shape)\n",
    "    d_b3_av = np.zeros(B3.shape)\n",
    "    d_b4_av = np.zeros(B4.shape)\n",
    "\n",
    "\n",
    "    for example_no in range(batch_size):\n",
    "        d_W2_t, d_W3_t, d_W4_t, d_b2_t, d_b3_t, d_b4_t = backprop(X, Y, W2, W3, W4, B2, B3, B4, batch_no, example_no)\n",
    "\n",
    "        d_W2_av += d_W2_t\n",
    "        d_W3_av += d_W3_t\n",
    "        d_W4_av += d_W4_t\n",
    "\n",
    "        d_b2_av += d_b2_t\n",
    "        d_b3_av += d_b3_t\n",
    "        d_b4_av += d_b4_t\n",
    "\n",
    "    d_W2_av = d_W2_av/batch_size\n",
    "    d_W3_av = d_W3_av/batch_size\n",
    "    d_W4_av = d_W4_av/batch_size\n",
    "\n",
    "    d_b2_av = d_b2_av/batch_size\n",
    "    d_b3_av = d_b3_av/batch_size\n",
    "    d_b4_av = d_b4_av/batch_size\n",
    "\n",
    "\n",
    "    W2_updated = W2 - (learning_rate*d_W2_av)\n",
    "    W3_updated = W3 - (learning_rate*d_W3_av)\n",
    "    W4_updated = W4 - (learning_rate*d_W4_av)\n",
    "\n",
    "    b2_updated = B2 - (learning_rate*d_b2_av)\n",
    "    b3_updated = B3 - (learning_rate*d_b3_av)\n",
    "    b4_updated = B4 - (learning_rate*d_b4_av) \n",
    "\n",
    "    return W2_updated, W3_updated, W4_updated, b2_updated, b3_updated, b4_updated \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run network for n epoches and output error \n",
    "\n",
    "def run(X_in, Y_in, epochs, learning_rate, mini_batch_size):\n",
    "\n",
    "\n",
    "    lowerw2, upperw2 = -(1.0 / sqrt(784)), (1.0 / sqrt(784 ))\n",
    "    lowerw3, upperw3 = -(1.0 / sqrt(16)), (1.0 / sqrt(16))\n",
    "    lowerw4, upperw4 = -(1.0 / sqrt(16)), (1.0 / sqrt(16))\n",
    "\n",
    "    lowerb2, upperb2 = -(1.0 / sqrt(16)), (1.0 / sqrt(16))\n",
    "    lowerb3, upperb3 = -(1.0 / sqrt(16)), (1.0 / sqrt(16))\n",
    "    lowerb4, upperb4 = -(1.0 / sqrt(10)), (1.0 / sqrt(10))\n",
    "\n",
    "    W2 = np.random.uniform(low = lowerw2, high= upperw2, size =(16, 784))\n",
    "    W3 = np.random.uniform(low = lowerw3, high= upperw3, size =(16, 16))\n",
    "    W4 = np.random.uniform(low = lowerw4, high= upperw4, size =(10, 16))\n",
    "\n",
    "    b2 = np.random.uniform(low = lowerb2, high= upperb2, size =(16, 1))\n",
    "    b3 = np.random.uniform(low = lowerb3, high= upperb4, size =(16, 1))\n",
    "    b4 = np.random.uniform(low = lowerb4, high= upperb4, size =(10, 1))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    for ep in range(epochs):\n",
    "\n",
    "        #shuffle data & generate mini batches\n",
    "\n",
    "        X, Y = create_mini_batch(X_in, Y_in, mini_batch_size)\n",
    "        cost_1 = 0\n",
    "        correct = 0\n",
    "        cost_array = []\n",
    "\n",
    "        for batch_n in range(int(len(X_in)/mini_batch_size)):\n",
    "\n",
    "            #gradient decent step here\n",
    "\n",
    "            W2, W3, W4, b2, b3, b4 = update_weights(X, Y, W2, W3, W4, b2, b3, b4, batch_n, mini_batch_size, learning_rate)\n",
    "\n",
    "            for example_num in range(mini_batch_size):\n",
    "\n",
    "                Z_2, a_2 = feedforward(X[batch_n][example_num].reshape(784,1), W2, b2)\n",
    "                Z_3, a_3 = feedforward(a_2, W3, b3)\n",
    "                Z_L, a_L = feedforward(a_3, W4, b4)\n",
    "\n",
    "\n",
    "                cost_1 += Cost_per_example(a_L, Y[batch_n][example_num])/mini_batch_size\n",
    "                \n",
    "                if np.argmax(a_L) == np.argmax(Y[batch_n][example_num]):\n",
    "                    correct += 1\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "        print(\"Epoch\",ep,\"Cost:\", cost_1)\n",
    "        cost_array.append(cost_1)\n",
    "\n",
    "\n",
    "        print(\"Epoch\", ep,\"Percentage: \", correct,\"/\", X_in.shape[0])\n",
    "\n",
    "    \n",
    "\n",
    "    return  W2, W3, W4, b2, b3, b4, cost_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Cost: 2083.7524295380153\n",
      "Epoch 0 Percentage:  3765 / 42000\n",
      "Epoch 1 Cost: 2095.35615301752\n",
      "Epoch 1 Percentage:  3760 / 42000\n"
     ]
    }
   ],
   "source": [
    "W2_new, W3_new, W4_new, b2_new, b3_new, b4_new, cost_array = run(X_train, y_train_binary, 2, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X, Y, W2, W3, W4, b2, b3, b4):\n",
    "\n",
    "    correct = 0\n",
    "\n",
    "    for example_num in range(X.shape[0]):\n",
    "\n",
    "        Z_2, a_2 = feedforward(X[example_num].reshape(784,1), W2, b2)\n",
    "        Z_3, a_3 = feedforward(a_2, W3, b3)\n",
    "        Z_L, a_L = feedforward(a_3, W4, b4)\n",
    "\n",
    "\n",
    "        if np.argmax(a_L) == np.argmax(Y[example_num]):\n",
    "            correct += 1\n",
    "\n",
    "\n",
    "    print(\"Correct =\", correct, \"/\", X.shape[0])\n",
    "    print(\"Percentage correct = \", (correct/X.shape[0])*100)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct = 1250 / 14000\n",
      "Percentage correct =  8.928571428571429\n"
     ]
    }
   ],
   "source": [
    "test(X_test, y_test_binary, W2_new, W3_new, W4_new, b2_new, b3_new, b4_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88c140aa648b729834400c23088e4467824ff5305599de806f499a26b691529b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
