{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw , y_raw = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_raw.shape)\n",
    "print(y_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframes converted into numpy arrays\n",
    "X_raw_np = X_raw.to_numpy()\n",
    "y_raw_np = y_raw.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.  18.  18.  18. 126. 136. 175.  26. 166. 255. 247. 127.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.  30.  36.  94. 154. 170. 253. 253. 253. 253. 253. 225. 172. 253. 242. 195.  64.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.  49. 238. 253. 253. 253. 253. 253. 253. 253. 253. 251.  93.  82.  82.  56.  39.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.  18. 219. 253. 253. 253. 253. 253. 198. 182. 247. 241.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.  80. 156. 107. 253. 253. 205.  11.   0.  43. 154.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.  14.   1. 154. 253.  90.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 139. 253. 190.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  11. 190. 253.  70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  35. 241. 225. 160. 108.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  81. 240. 253. 253. 119.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  45. 186. 253. 253. 150.  27.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  16.  93. 252. 253. 187.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 249. 253. 249.  64.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  46. 130. 183. 253. 253. 207.   2.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  39. 148. 229. 253. 253. 253. 250. 182.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  24. 114. 221. 253. 253. 253. 253. 201.  78.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.  23.  66. 213. 253. 253. 253. 253. 198.  81.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.  18. 171. 219. 253. 253. 253. 253. 195.  80.   9.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.  55. 172. 226. 253. 253. 253. 253. 244. 133.  11.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0. 136. 253. 253. 253. 212. 135. 132.  16.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "#Thought it'd be cool to see the images as a matrix\n",
    "\n",
    "np.set_printoptions(linewidth=2000)\n",
    "print(X_raw_np[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label is 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index=0\n",
    "\n",
    "plt.imshow(X_raw_np[index].reshape(28,28), cmap=cm.binary)\n",
    "print(\"Label is\", y_raw_np[index])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data split into 60% training, 20% validation & 20% test\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_raw_np, y_raw_np, test_size=0.4)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train = (42000, 784)\n",
      "y_train = (42000,)\n",
      "X_val = (14000, 784)\n",
      "y_val = (14000,)\n",
      "X_test = (14000, 784)\n",
      "y_test = (14000,)\n"
     ]
    }
   ],
   "source": [
    "#Checking dimensions\n",
    "\n",
    "print(\"X_train =\",X_train.shape)\n",
    "print(\"y_train =\",y_train.shape)\n",
    "print(\"X_val =\", X_val.shape)\n",
    "print(\"y_val =\", y_val.shape)\n",
    "print(\"X_test =\", X_test.shape)\n",
    "print(\"y_test =\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing values to between 0-1 \n",
    "X_train, X_val, X_test = np.array(X_train/255), np.array(X_val/255), np.array(X_test/255)\n",
    "\n",
    "\n",
    "# Changing y data into binary matricies such that each row is a vector with 0s and 1 which indicates the label.\n",
    "# this is done so that a MSE error can be calulated while using sigmoid activation function for the output layer.\n",
    "\n",
    "\n",
    "#y_train into binary matrix\n",
    "y_train_binary = np.zeros((42000,10))\n",
    "\n",
    "j = 0\n",
    "for i in range(0, len(y_train)):\n",
    "    \n",
    "\n",
    "\n",
    "    if int(y_train[i]) == 0:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_train[i]) == 1:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_train[i]) == 2:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "    elif int(y_train[i]) == 3:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_train[i]) == 4:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_train[i]) == 5:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "    elif int(y_train[i]) == 6:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_train[i]) == 7:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_train[i]) == 8:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_train[i]) == 9:\n",
    "        \n",
    "        y_train_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1]) \n",
    "        j += 1\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "#y_val into binary matrix\n",
    "y_val_binary = np.zeros((14000,10))\n",
    "\n",
    "j = 0\n",
    "for i in range(0, len(y_val)):\n",
    "    \n",
    "\n",
    "\n",
    "    if int(y_val[i]) == 0:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_val[i]) == 1:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_val[i]) == 2:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "    elif int(y_val[i]) == 3:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_val[i]) == 4:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_val[i]) == 5:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "    elif int(y_val[i]) == 6:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_val[i]) == 7:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_val[i]) == 8:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_val[i]) == 9:\n",
    "        \n",
    "        y_val_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1]) \n",
    "        j += 1\n",
    "\n",
    "\n",
    "\n",
    "#y_test into binary matrix\n",
    "y_test_binary = np.zeros((14000,10))\n",
    "\n",
    "j = 0\n",
    "for i in range(0, len(y_test)):\n",
    "    \n",
    "\n",
    "\n",
    "    if int(y_test[i]) == 0:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_test[i]) == 1:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_test[i]) == 2:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "    elif int(y_test[i]) == 3:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_test[i]) == 4:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_test[i]) == 5:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0]) \n",
    "        j += 1\n",
    "    elif int(y_test[i]) == 6:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_test[i]) == 7:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_test[i]) == 8:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0]) \n",
    "        j += 1\n",
    "\n",
    "    elif int(y_test[i]) == 9:\n",
    "        \n",
    "        y_test_binary[j] +=  np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1]) \n",
    "        j += 1\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **NN begins**\n",
    "\n",
    "##### In this implementation everything is manually coded.\n",
    "\n",
    "##### NN specification:\n",
    "\n",
    "L = 4, L1 has 784 neurons, 2 hidden layers have 16 neurons each and the output layer has 10, one for each digit.\n",
    "\n",
    "\n",
    "W2 has dimensions 16 x 784 <br>\n",
    "W3 has dimensions 16 x 16 <br>\n",
    "W4 has dimensions 10 x 16 <br>\n",
    "\n",
    "b2-3 has dimensions 16 x 1 <br>\n",
    "b4 has dimensions 10 x 1 <br>\n",
    "\n",
    "\n",
    "##### Procedure:\n",
    "1. Manually generate all weight matricies and biases then initalize randomly \n",
    "\n",
    "***\n",
    "\n",
    "2. Split data into mini batches\n",
    "3. Feedforward a single training example from a given batch\n",
    "4. Calulate cost \n",
    "5. Backprop and calulate the gradient\n",
    "\n",
    "***\n",
    "\n",
    "6. Repeat steps 3-5 for all images in first batch\n",
    "\n",
    "***\n",
    "\n",
    "7. Average the gradient of the cost for all images in the first batch\n",
    "8. apply gradient decent step to update the weights\n",
    "\n",
    "***\n",
    "\n",
    "9. Repeat 3-8 for all minibatches\n",
    "\n",
    "***\n",
    "10. shuffle data\n",
    "11. Repeat 2-9 for a given number of 'epochs' \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating and initializing matricies & biases randomly to values between -5 - 5\n",
    "\n",
    "#W2 = np.random.uniform(low = -5,high= 5,size =(16, 784))\n",
    "#W3 = np.random.uniform(low = -5,high= 5,size =(16, 16))\n",
    "#W4 = np.random.uniform(low = -5,high= 5,size =(10, 16))\n",
    "\n",
    "#b2 = np.random.uniform(low = -5,high= 5,size =(16, 1))\n",
    "#b3 = np.random.uniform(low = -5,high= 5,size =(16, 1))\n",
    "#b4 = np.random.uniform(low = -5,high= 5,size =(10, 1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for shuffling and creating mini batches by turning X and y into tensors\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def create_mini_batch(X_input, y_input, mini_batch_size):\n",
    "\n",
    "    X_shuffled, y_shuffled = shuffle(X_input, y_input)\n",
    "\n",
    "    reshaped_dim = int(len(X_shuffled)/mini_batch_size)\n",
    "\n",
    "    X_minibatches_tensor = X_shuffled.reshape(reshaped_dim, mini_batch_size,  X_shuffled.shape[1] )\n",
    "\n",
    "    y_minibatches_tensor = y_shuffled.reshape(reshaped_dim, mini_batch_size,  y_shuffled.shape[1])\n",
    "\n",
    "\n",
    "    return X_minibatches_tensor, y_minibatches_tensor\n",
    "\n",
    "\n",
    "# The above function outputs a X tensor such that each matrix being a mini batch with each row being an image\n",
    "# it outputs y a 3 tendor with the input being the y binary matricies. the matricies of the tensor are a given minibatch\n",
    "#  and the rows are the labels of each image. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "# Derivative of sigmoid \n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z)*(1.0-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedsforward one layer and outputs Z and activations of the next layer. \n",
    "def feedforward(a, W, b):\n",
    "    Z_l = np.dot(W, a) + b\n",
    "    A_l = sigmoid(Z_l)\n",
    "\n",
    "    return Z_l, A_l \n",
    "\n",
    "#input data X needs to be fed in column vec form .reshape(784, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE cost function\n",
    "\n",
    "def Cost_per_example(a_L, Y):\n",
    "    e2 = ((a_L - Y)**2)/2\n",
    "    cost = e2.sum()\n",
    "    return cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backpropagation\n",
    "\n",
    "def backprop(X, Y, W2, W3, W4, B2, B3, B4, batch_no, example_no):\n",
    "\n",
    "    \n",
    "    Z_2, a_2 = feedforward(X[batch_no][example_no].reshape(784,1), W2, B2)\n",
    "    Z_3, a_3 = feedforward(a_2, W3, B3)\n",
    "    Z_L, a_L = feedforward(a_3, W4, B4)\n",
    "\n",
    "    delta_L = np.multiply(((a_L - Y[batch_no][example_no].reshape(10,1))**2), sigmoid_prime(Z_L))\n",
    "    delta_3 = np.multiply(np.dot(W4.T, delta_L), sigmoid_prime(Z_3))\n",
    "    delta_2 = np.multiply(np.dot(W3.T, delta_3), sigmoid_prime(Z_2))\n",
    "\n",
    "    #creating derivatives of cost w.r.t weight matricies\n",
    "\n",
    "    d_W4 = np.zeros((10, 16))\n",
    "    for j in range(10):\n",
    "        for k in range(16):\n",
    "            d_W4[j][k] += delta_L[j]*a_3[k]\n",
    "\n",
    "    d_W3 = np.zeros((16, 16))\n",
    "    for j in range(16):\n",
    "        for k in range(16):\n",
    "            d_W3[j][k] += delta_3[j]*a_2[k]\n",
    "\n",
    "\n",
    "    d_W2 = np.zeros((16, 784))\n",
    "    for j in range(16):\n",
    "        for k in range(784):\n",
    "            d_W2[j][k] += delta_2[j]*X[batch_no][example_no].reshape(784,1)[k]\n",
    "\n",
    "\n",
    "    d_b4, d_b3, d_b2 = delta_L, delta_3, delta_2\n",
    "\n",
    "\n",
    "    return d_W2, d_W3, d_W4, d_b2, d_b3, d_b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that updates the weights using gradient decent \n",
    "\n",
    "def update_weights(X, Y, W2, W3, W4, B2, B3, B4, batch_no, batch_size, learning_rate):\n",
    "\n",
    "    d_W2_av = np.zeros(W2.shape)\n",
    "    d_W3_av = np.zeros(W3.shape)\n",
    "    d_W4_av = np.zeros(W4.shape)\n",
    "\n",
    "    d_b2_av = np.zeros(B2.shape)\n",
    "    d_b3_av = np.zeros(B3.shape)\n",
    "    d_b4_av = np.zeros(B4.shape)\n",
    "\n",
    "\n",
    "    for example_no in range(batch_size):\n",
    "        d_W2_t, d_W3_t, d_W4_t, d_b2_t, d_b3_t, d_b4_t = backprop(X, Y, W2, W3, W4, B2, B3, B4, batch_no, example_no)\n",
    "\n",
    "        d_W2_av += d_W2_t\n",
    "        d_W3_av += d_W3_t\n",
    "        d_W4_av += d_W4_t\n",
    "\n",
    "        d_b2_av += d_b2_t\n",
    "        d_b3_av += d_b3_t\n",
    "        d_b4_av += d_b4_t\n",
    "\n",
    "    d_W2_av = d_W2_av/batch_size\n",
    "    d_W3_av = d_W3_av/batch_size\n",
    "    d_W4_av = d_W4_av/batch_size\n",
    "\n",
    "    d_b2_av = d_b2_av/batch_size\n",
    "    d_b3_av = d_b3_av/batch_size\n",
    "    d_b4_av = d_b4_av/batch_size\n",
    "\n",
    "\n",
    "    W2_updated = W2 - learning_rate*d_W2_av\n",
    "    W3_updated = W3 - learning_rate*d_W3_av\n",
    "    W4_updated = W4 - learning_rate*d_W4_av\n",
    "\n",
    "    b2_updated = B2 - learning_rate*d_b2_av\n",
    "    b3_updated = B3 - learning_rate*d_b3_av\n",
    "    b4_updated = B4 - learning_rate*d_b4_av \n",
    "\n",
    "    return W2_updated, W3_updated, W4_updated, b2_updated, b3_updated, b4_updated \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run network for n epoches and output error \n",
    "\n",
    "def run(X_in, Y_in, epochs, learning_rate, mini_batch_size):\n",
    "\n",
    "\n",
    "    W2 = np.random.uniform(low = -5,high= 5,size =(16, 784))\n",
    "    W3 = np.random.uniform(low = -5,high= 5,size =(16, 16))\n",
    "    W4 = np.random.uniform(low = -5,high= 5,size =(10, 16))\n",
    "\n",
    "    b2 = np.random.uniform(low = -5,high= 5,size =(16, 1))\n",
    "    b3 = np.random.uniform(low = -5,high= 5,size =(16, 1))\n",
    "    b4 = np.random.uniform(low = -5,high= 5,size =(10, 1))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    for ep in range(epochs):\n",
    "\n",
    "        #shuffle data & generate mini batches\n",
    "\n",
    "        X, Y = create_mini_batch(X_in, Y_in, mini_batch_size)\n",
    "        cost_1 = 0\n",
    "        correct = 0\n",
    "        cost_array = []\n",
    "\n",
    "        for batch_n in range(int(len(X_in)/mini_batch_size)):\n",
    "\n",
    "            #gradient decent step here\n",
    "\n",
    "            W2, W3, W4, b2, b3, b4 = update_weights(X, Y, W2, W3, W4, b2, b3, b4, batch_n, mini_batch_size, learning_rate)\n",
    "\n",
    "            for example_num in range(mini_batch_size):\n",
    "\n",
    "                Z_2, a_2 = feedforward(X[batch_n][example_num].reshape(784,1), W2, b2)\n",
    "                Z_3, a_3 = feedforward(a_2, W3, b3)\n",
    "                Z_L, a_L = feedforward(a_3, W4, b4)\n",
    "\n",
    "\n",
    "                cost_1 += Cost_per_example(a_L, Y[batch_n][example_num])/mini_batch_size\n",
    "                \n",
    "                if np.argmax(a_L) == np.argmax(Y[batch_n][example_num]):\n",
    "                    correct += 1\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "        print(\"Epoch\",ep,\"Cost:\", cost_1)\n",
    "        cost_array.append(cost_1)\n",
    "\n",
    "\n",
    "        print(\"Epoch\", ep,\"Percentage: \", correct,\"/\", X_in.shape[0])\n",
    "\n",
    "    \n",
    "\n",
    "    return  W2, W3, W4, b2, b3, b4, cost_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17119/3723144574.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mW2_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW3_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW4_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb3_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb4_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_17119/1839604682.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(X_in, Y_in, epochs, learning_rate, mini_batch_size)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m#gradient decent step here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mexample_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_17119/2710615339.py\u001b[0m in \u001b[0;36mupdate_weights\u001b[0;34m(X, Y, W2, W3, W4, B2, B3, B4, batch_no, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mexample_no\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0md_W2_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_W3_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_W4_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_b2_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_b3_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_b4_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0md_W2_av\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0md_W2_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_17119/4119476658.py\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(X, Y, W2, W3, W4, B2, B3, B4, batch_no, example_no)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0md_W2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdelta_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_no\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample_no\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "W2_new, W3_new, W4_new, b2_new, b3_new, b4_new, cost_array = run(X_train, y_train_binary, 10, 3.0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X, Y, W2, W3, W4, b2, b3, b4):\n",
    "\n",
    "    correct = 0\n",
    "\n",
    "    for example_num in range(X.shape[0]):\n",
    "\n",
    "        Z_2, a_2 = feedforward(X[batch_n][example_num].reshape(784,1), W2, b2)\n",
    "        Z_3, a_3 = feedforward(a_2, W3, b3)\n",
    "        Z_L, a_L = feedforward(a_3, W4, b4)\n",
    "\n",
    "\n",
    "        if np.argmax(a_L) == np.argmax(Y[example_num]):\n",
    "            correct += 1\n",
    "\n",
    "\n",
    "    print(\"Correct =\", correct, \"/\", X.shape[0])\n",
    "    print(\"Percentage correct = \", (correct/X.shape[0])*100)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64e80eab9906f9954411e2ed9e2f50267578aafb496993537603541cb035db4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
